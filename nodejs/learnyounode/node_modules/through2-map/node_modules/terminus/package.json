{
  "name": "terminus",
  "version": "1.0.12",
  "description": "An abstraction for making stream.Writable streams without all the boilerplate.",
  "main": "terminus.js",
  "directories": {
    "example": "examples",
    "test": "test"
  },
  "scripts": {
    "test": "node test/"
  },
  "browser": {
    "readable-stream/writable": "_stream_writable"
  },
  "keywords": [
    "streams",
    "streams2",
    "concat",
    "tail",
    "devnull"
  ],
  "author": {
    "name": "Bryce B. Baril"
  },
  "license": "MIT",
  "dependencies": {
    "readable-stream": "~1.0.33",
    "xtend": "~4.0.0"
  },
  "devDependencies": {
    "babelify": "~6.1.2",
    "stream-spigot": "~3.0.5",
    "tape": "~4.0.0",
    "through2-spy": "~1.2.0"
  },
  "browserify": {
    "transform": [
      "babelify"
    ]
  },
  "repository": {
    "type": "git",
    "url": "git://github.com/brycebaril/node-terminus.git"
  },
  "bugs": {
    "url": "https://github.com/brycebaril/node-terminus/issues"
  },
  "readme": "terminus\n=====\n\n[![NPM](https://nodei.co/npm/terminus.png)](https://nodei.co/npm/terminus/)\n\n`terminus` makes it easier to create streams2 Writable streams. You can either use it like `through2` to eliminate subclassing boilerplate, or use one of the provided helper terminus streams.\n\n```javascript\nvar terminus = require(\"terminus\")\nvar through2 = require(\"through2\")\nvar spigot = require(\"stream-spigot\")\n\n// Streams2 all the way down...\n\nfunction uc(chunk, encoding, callback) {\n  this.push(chunk.toString().toUpperCase())\n  callback()\n}\n\nfunction log(chunk, encoding, callback) {\n  // This example is very contrived, you're likely better off directly piping to `process.stdout`\n  console.log(chunk.toString())\n  callback()\n}\n\nspigot([\"my \", \"dog \", \"has \", \"fleas\"])\n  .pipe(through2(uc))\n  .pipe(terminus(log))\n\n/*\nMY\nDOG\nHAS\nFLEAS\n*/\n\n// devnull\n\nvar spy = require(\"through2-spy\")\n\nspigot([\"my \", \"dog \", \"has \", \"fleas\"])\n  .pipe(spy({highWaterMark: 2}, function (buf) {console.log(buf.toString())}))\n  .pipe(terminus.devnull())\n\n/*\nmy\ndog\nhas\nfleas\n*/\n\n// concat\n\nfunction reverse(contents) {\n  console.log(contents.toString().split(\"\").reverse().join(\"\"))\n}\n\nspigot([\"my \", \"dog \", \"has \", \"fleas\"])\n  .pipe(terminus.concat(reverse))\n\n/*\nsaelf sah god ym\n*/\n\n// tail\n\nvar chunkLengths = []\nfunction logLength(chunk) {\n  chunkLengths.push(chunk.length)\n}\n\nvar ws = terminus.tail(logLength)\nws.on(\"finish\", function () {\n  console.log(chunkLengths)\n})\n\nspigot([\"my \", \"dog \", \"has \", \"fleas\"])\n  .pipe(ws)\n\n/*\n[ 3, 4, 4, 5 ]\n*/\n\n// objectMode\n\nvar s = spigot({objectMode: true}, [\n  {foo: 1},\n  {foo: 2},\n  {foo: 3},\n  {foo: 4},\n])\n\nfunction timesTwo(record, encoding, callback) {\n  record.foo *= 2\n  this.push(record)\n  callback()\n}\n\nfunction logRecords(records) {\n  console.log(records)\n}\n\ns.pipe(through2({objectMode: true}, timesTwo))\n .pipe(terminus.concat({objectMode: true}, logRecords))\n\n/*\n[ { foo: 2 }, { foo: 4 }, { foo: 6 }, { foo: 8 } ]\n*/\n```\n\nAPI\n===\n\n`terminus([options,] _writeFunction)`\n---\n\nCreate a `streams.Writable` instance that will call `_writeFunction` on every chunk. Consult the [stream.Writable](http://nodejs.org/api/stream.html#stream_class_stream_writable_1) documentation for instructions on creating a `_write` function.\n\n`terminus.ctor([options,] _writeFunction)`\n---\n\nCreate a `streams.Writable` Subclass that can be used to re-create stream.Writable instances with the same _writeFunction.\n\n`terminus.devnull([options])`\n---\n\nCreate a `stream.Writable` instance that is akin to writing to `dev/null` i.e. it doesn't do anything except give your stream somewhere to go.\n\nWhy? Because if your pipeline doesn't terminate on a Writable stream, it will get paused at the High Water Mark with nothing to unpause it. I've most often seen this when people are using PassThrough streams, or Transforms that incorporate all required behavior.\n\n`terminus.concat([options], fn)`\n---\n\nCollect the entire stream and when it is done, call `fn(contents)`. This is similar to the stream behavior of [concat-stream](http://npm.im/concat-stream) without the extra Array/Buffer concat behavior and entirely in streams2.\n\n`terminus.tail([options], fn)`\n---\n\nA slightly less complicated version of `terminus([options,] _writeFunction)` that only requries you to provide a function that operates as `fn(chunk, encoding)`.\n\noptions\n---\n\nAll functions accept standard `streams.Writable` options, that is:\n\n  * highWaterMark `[Number]` Buffer level when write() starts returning false. `Default=16kb`\n  * decodeStrings `[Boolean]` Whether not to decode strings into Buffers before passing them to _write() `Default=true`\n  * objectMode `[Boolean]` If the content is Javascript objects versus strings/buffers. `Default=false`\n\nobjectMode\n---\n\nThe most common option you'll be setting is `objectMode` which will enable you to stream Javascript objects, e.g. records. Unfortunately this is currently required and **ALL** streams2 parts of your stream pipeline must be in `objectMode` or you'll get errors. It's annoying, I know.\n\nLICENSE\n=======\n\nMIT\n",
  "readmeFilename": "README.md",
  "_id": "terminus@1.0.12",
  "_from": "terminus@~1.0.10"
}
